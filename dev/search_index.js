var documenterSearchIndex = {"docs":
[{"location":"advanced_usage/#Advanced-Usage","page":"Advanced Usage","title":"Advanced Usage","text":"","category":"section"},{"location":"advanced_usage/#Fine-Tuning-Optimization:","page":"Advanced Usage","title":"Fine-Tuning Optimization:","text":"","category":"section"},{"location":"advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"The optimize function offers several parameters for fine-tuning the optimization process:","category":"page"},{"location":"advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"max_iterations: Sets the maximum number of iterations to perform. Increasing this value may improve the accuracy of the result but will require more computational time.\nmin_radius: Specifies the minimum allowable size of the hyper-rectangles. This can be adjusted to control the granularity of the search.","category":"page"},{"location":"advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"Example with custom parameters:","category":"page"},{"location":"advanced_usage/","page":"Advanced Usage","title":"Advanced Usage","text":"result = DividedRectangles.optimize(f, a, b, max_iterations=500, min_radius=1e-6)","category":"page"},{"location":"credits/#Credits","page":"Credits","title":"Credits","text":"","category":"section"},{"location":"credits/","page":"Credits","title":"Credits","text":"Contributors to this package include Anshrin Srivastava, Mykel Kochenderfer, Dylan Asmar, and Tim Wheeler.","category":"page"},{"location":"theory/#Theory","page":"Theory","title":"Theory","text":"","category":"section"},{"location":"theory/","page":"Theory","title":"Theory","text":"The DIRECT (DIvided RECTangles) algorithm is a global optimization method that does not require a known Lipschitz constant. This characteristic makes it particularly robust and versatile, applicable to a wide range of optimization problems. The algorithm operates by dividing the search space into smaller hyper-rectangles and evaluating the function at the center of each rectangle.","category":"page"},{"location":"theory/#Key-Concepts-of-the-DIRECT-Algorithm","page":"Theory","title":"Key Concepts of the DIRECT Algorithm","text":"","category":"section"},{"location":"theory/","page":"Theory","title":"Theory","text":"Division of Search Space:\nThe algorithm begins by treating the entire feasible region as a single hyper-rectangle.\nThis hyper-rectangle is then divided into smaller rectangles by splitting the dimensions.\nFunction Evaluation:\nThe function is evaluated at the center of each hyper-rectangle.\nThis evaluation helps in identifying the most promising regions for further exploration.\nSelection of Potentially Optimal Rectangles:\nAfter evaluation, the algorithm identifies potentially optimal rectangles. A rectangle is considered potentially optimal if it could contain the global minimum based on the evaluations performed so far.\nRecursive Division:\nThe selected rectangles are further divided, and the process repeats.\nThe algorithm continues to refine the search by focusing more on regions that are likely to contain the global minimum.","category":"page"},{"location":"theory/#Mathematical-Formulation","page":"Theory","title":"Mathematical Formulation","text":"","category":"section"},{"location":"theory/","page":"Theory","title":"Theory","text":"The algorithm relies on the following core mathematical principles:","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"Evaluation Function:   The objective function ( f(x) ) is evaluated at the center of each hyper-rectangle:","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"f(x) = sum_i=1^n c_i x_i","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"where ( xi ) are the variables, and ( ci ) are the corresponding coefficients.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"Rectangle Selection Criterion: A rectangle ( R ) is considered potentially optimal if:","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"  f(x_R) - L cdot r_R leq f(x) - L cdot r_x quad textfor all  x in R","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"where:","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"( f(x_R) ) is the function value at the center of the rectangle.\n( r_R ) is the radius of the rectangle.\n( L ) is the Lipschitz constant.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"Recursive Division:   The hyper-rectangles are recursively divided along their longest dimension:","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"x_R = fraca_i + b_i2","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"where ( ai ) and ( bi ) are the bounds of the rectangle along the ( i )-th dimension.","category":"page"},{"location":"theory/#Strengths-of-the-DIRECT-Algorithm","page":"Theory","title":"Strengths of the DIRECT Algorithm","text":"","category":"section"},{"location":"theory/","page":"Theory","title":"Theory","text":"The strength of the DIRECT algorithm lies in its ability to systematically explore the entire search space while focusing on the most promising areas. This systematic coverage helps the algorithm escape local minima, making it particularly effective for objective functions with multiple local minima.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"By not requiring the Lipschitz constant, the DIRECT algorithm is adaptable to various optimization problems, including those where the smoothness of the objective function is not well understood.","category":"page"},{"location":"usage/#Usage","page":"Usage","title":"Usage","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"To use the DividedRectangles module, start your code with:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"using DividedRectangles","category":"page"},{"location":"usage/#Core-Functions","page":"Usage","title":"Core Functions","text":"","category":"section"},{"location":"usage/#optimize","page":"Usage","title":"optimize","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"The optimize function is the primary function of the DividedRectangles module. It implements the DIRECT algorithm to find the minimum of a given objective function within specified bounds.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"To use the optimize function with a custom mathematical function:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"using DividedRectangles\n\n# Define the objective function\nf(x) = sum(c * xi for (c, xi) in zip(coeffs, x))\n\n# Call the optimization function\nresult = optimize(f, a, b)\n\nprintln(\"Optimal value found at: \", result)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Arguments:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"f: The objective function to be minimized.\na: Vector of lower bounds for the search space.\nb: Vector of upper bounds for the search space.\nmax_iterations: (Optional) The maximum number of iterations (default: 100).\nmin_radius: (Optional) The minimum radius of hyper-rectangles (default: 1e-5).","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Returns: ","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"A vector representing the coordinates of the optimal point found.","category":"page"},{"location":"usage/#Example:-Univariate-Optimization","page":"Usage","title":"Example: Univariate Optimization","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"The following example demonstrates how to use the DIRECT algorithm to find the minimum of a univariate function:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"using DividedRectangles\n\n# Define the objective function\nf(x) = sin(5 * x) + cos(2 * x)\n\n# Set the search bounds\na = [-1.0]\nb = [2.0]\n\n# Optimize\nresult = DividedRectangles.optimize(f, a, b)\n\nprintln(\"Optimal value found at: \", result)","category":"page"},{"location":"usage/#Example:-Multivariate-Optimization","page":"Usage","title":"Example: Multivariate Optimization","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"The following example shows how to optimize a multivariate function using the DIRECT algorithm:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"using DividedRectangles\n\n# Define the objective function\nf(x) = x[1]^2 + x[2]^2 + 3 * sin(5 * x[1]) + 2 * cos(3 * x[2])\n\n# Set the search bounds\na = [-2.0, -2.0]\nb = [2.0, 2.0]\n\n# Optimize\nresult = DividedRectangles.optimize(f, a, b)\n\nprintln(\"Optimal value found at: \", result)","category":"page"},{"location":"usage/#Parameters","page":"Usage","title":"Parameters","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"f: This is the objective function to minimize. Should be an operation that accepts a vector of Float64 values.\na: A vector with the lower bounds to be used in the search space.\nb: An upper-bound vector for the search space.\nmax_iterations:  Maximum number of iterations to run the optimization. The default is 100.\nmin_radius: The minimum allowable size of a hyper-rectangle (default: '1e-5').","category":"page"},{"location":"installation/#Installation","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"installation/","page":"Installation","title":"Installation","text":"To install the package, start Julia and run the following command:","category":"page"},{"location":"installation/","page":"Installation","title":"Installation","text":"using Pkg\nPkg.add(url=\"https://github.com/sisl/DividedRectangles.jl\")\n","category":"page"},{"location":"visualization/#Visualization","page":"Visualization","title":"Visualization","text":"","category":"section"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"To better understand the optimization process, here are visualizations that represent different stages and aspects of the DIRECT algorithm's progress:","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"(Image: Image 14)","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"The left contour plot shows the Lipschitz lower bound using five function evaluations. The right contour plot shows the approximation made by DIRECT, which divides the region into hyper-rectangles—one centered about each design point. Making this assumption allows for the rapid calculation of the minimum of the lower bound.","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"(Image: Image 12)","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"The Lipschitz lower bound for different Lipschitz constants (l). The estimated minimum changes locally as the Lipschitz constant is varied, and the region in which the minimum lies can also vary.","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"(Image: Image 13)","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"The DIRECT lower bound for different Lipschitz constants (l). The lower bound is not continuous, and while the minimum does not change locally, it can change regionally as the Lipschitz constant changes.","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"(Image: Image 21)","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"Center-point sampling using the DIRECT scheme, which divides intervals into thirds.","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"(Image: Image 18)","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"Potentially-optimal hyper-rectangle identification for a particular Lipschitz constant (l). Black dots represent DIRECT hyper-rectangles and their location in (f(c), r) space. The potentially optimal hyper-rectangles form a piecewise-linear boundary along the lower-right of this space.","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"(Image: Image 20)","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"The potentially optimal intervals for the DIRECT method form a piecewise boundary that encloses all intervals along the lower-right.","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"(Image: Image 17)","category":"page"},{"location":"visualization/","page":"Visualization","title":"Visualization","text":"The DIRECT method after 16 iterations on the Branin function. Each cell is bordered by white lines. The cells are much denser around the minima of the Branin function, as the DIRECT method procedurally increases its resolution in those regions.","category":"page"},{"location":"#DividedRectangles.jl","page":"Home","title":"DividedRectangles.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: CI) (Image: Documentation Status) (Image: codecov) –-","category":"page"},{"location":"","page":"Home","title":"Home","text":"DividedRectangles.jl provides an implementation of the DIRECT (DIvided RECTangles) algorithm for global optimization. The DIRECT algorithm is particularly useful for optimizing functions where the Lipschitz constant is unknown. This package allows users to perform both univariate and multivariate optimization efficiently.","category":"page"},{"location":"#Key-Equation:","page":"Home","title":"Key Equation:","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The algorithm is guided by the following fundamental equation:","category":"page"},{"location":"","page":"Home","title":"Home","text":"f(x) = sum_i=1^n c_i x_i","category":"page"},{"location":"","page":"Home","title":"Home","text":"where:","category":"page"},{"location":"","page":"Home","title":"Home","text":"( x_i ) represents the variables.\n( c_i ) represents the coefficients corresponding to each variable.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This equation forms the basis for dividing the search space into smaller rectangles, optimizing the function by evaluating it at specific points.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"This documentation provides detailed usage examples, theoretical background, and advanced customization options to help you get the most out of DividedRectangles.jl.","category":"page"}]
}
